{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/raft-baselines/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading builder script: 100%|██████████| 11.9k/11.9k [00:00<00:00, 17.8MB/s]\n",
      "Downloading metadata: 100%|██████████| 56.1k/56.1k [00:00<00:00, 257kB/s]\n",
      "Downloading readme: 100%|██████████| 15.2k/15.2k [00:00<00:00, 31.4MB/s]\n",
      "Downloading data: 100%|██████████| 7.79k/7.79k [00:00<00:00, 10.3MB/s]\n",
      "Downloading data: 100%|██████████| 662k/662k [00:01<00:00, 639kB/s]\n",
      "Downloading data: 100%|██████████| 3.91k/3.91k [00:00<00:00, 14.4MB/s]\n",
      "Downloading data: 100%|██████████| 327k/327k [00:00<00:00, 439kB/s]\n",
      "Downloading data: 100%|██████████| 11.5k/11.5k [00:00<00:00, 11.0MB/s]\n",
      "Downloading data: 100%|██████████| 917k/917k [00:01<00:00, 912kB/s] \n",
      "Downloading data: 100%|██████████| 54.8k/54.8k [00:00<00:00, 271kB/s]]\n",
      "Downloading data: 100%|██████████| 1.59M/1.59M [00:01<00:00, 1.37MB/s]\n",
      "Downloading data: 100%|██████████| 70.0k/70.0k [00:00<00:00, 236kB/s]]\n",
      "Downloading data: 100%|██████████| 196k/196k [00:00<00:00, 372kB/s]\n",
      "Downloading data: 100%|██████████| 7.58k/7.58k [00:00<00:00, 7.49MB/s]\n",
      "Downloading data: 100%|██████████| 412k/412k [00:00<00:00, 539kB/s]\n",
      "Downloading data: 100%|██████████| 52.5k/52.5k [00:00<00:00, 267kB/s]]\n",
      "Downloading data: 100%|██████████| 2.31M/2.31M [00:01<00:00, 1.82MB/s]\n",
      "Downloading data: 100%|██████████| 201k/201k [00:00<00:00, 377kB/s]it]\n",
      "Downloading data: 100%|██████████| 2.09M/2.09M [00:01<00:00, 1.56MB/s]\n",
      "Downloading data: 100%|██████████| 7.64k/7.64k [00:00<00:00, 9.48MB/s]\n",
      "Downloading data: 100%|██████████| 412k/412k [00:00<00:00, 539kB/s]\n",
      "Downloading data: 100%|██████████| 5.38k/5.38k [00:00<00:00, 6.29MB/s]\n",
      "Downloading data: 100%|██████████| 336k/336k [00:00<00:00, 482kB/s]\n",
      "Downloading data: 100%|██████████| 8.12k/8.12k [00:00<00:00, 7.79MB/s]]\n",
      "Downloading data: 100%|██████████| 68.5k/68.5k [00:00<00:00, 263kB/s]\n",
      "Downloading data files: 100%|██████████| 11/11 [00:53<00:00,  4.87s/it]\n",
      "Extracting data files: 100%|██████████| 11/11 [00:00<00:00, 1328.19it/s]\n",
      "Generating train split: 100%|██████████| 50/50 [00:00<00:00, 7396.84 examples/s]\n",
      "Generating test split: 100%|██████████| 5000/5000 [00:00<00:00, 41835.86 examples/s]\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "banking_77_ought = datasets.load_dataset(\n",
    "    \"ought/raft\", \"banking_77\", split=\"train\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 665/665 [00:00<00:00, 116kB/s]\n",
      "Downloading (…)olve/main/vocab.json: 100%|██████████| 1.04M/1.04M [00:01<00:00, 1.02MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 600kB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 1.36M/1.36M [00:01<00:00, 1.28MB/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Path /root/raft-baselines/src/raft_baselines/models/banking_77 not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/root/raft-baselines/src/raft_baselines/scripts/save_models.ipynb Cell 2\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://tunnel%2Bp5sn33vg13y4z1/root/raft-baselines/src/raft_baselines/scripts/save_models.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mraft_baselines\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mclassifiers\u001b[39;00m \u001b[39mimport\u001b[39;00m SetFitClassifier\n\u001b[0;32m----> <a href='vscode-notebook-cell://tunnel%2Bp5sn33vg13y4z1/root/raft-baselines/src/raft_baselines/scripts/save_models.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m classifier \u001b[39m=\u001b[39m SetFitClassifier(\n\u001b[1;32m      <a href='vscode-notebook-cell://tunnel%2Bp5sn33vg13y4z1/root/raft-baselines/src/raft_baselines/scripts/save_models.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     training_data\u001b[39m=\u001b[39;49mbanking_77_ought,\n\u001b[1;32m      <a href='vscode-notebook-cell://tunnel%2Bp5sn33vg13y4z1/root/raft-baselines/src/raft_baselines/scripts/save_models.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     config\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mbanking_77\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell://tunnel%2Bp5sn33vg13y4z1/root/raft-baselines/src/raft_baselines/scripts/save_models.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m )\n",
      "File \u001b[0;32m~/raft-baselines/src/raft_baselines/classifiers/set_fit_classifier.py:60\u001b[0m, in \u001b[0;36mSetFitClassifier.__init__\u001b[0;34m(self, training_data, config, model_type, model_head, loss_class, batch_size, num_epochs, num_iterations, max_tokens, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mif\u001b[39;00m config \u001b[39min\u001b[39;00m PRE_SAVED_MODELS:\n\u001b[1;32m     58\u001b[0m     \u001b[39m# load from ../models/config\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     path \u001b[39m=\u001b[39m Path(\u001b[39m__file__\u001b[39m)\u001b[39m.\u001b[39mparent\u001b[39m.\u001b[39mparent\u001b[39m.\u001b[39mjoinpath(\u001b[39m\"\u001b[39m\u001b[39mmodels\u001b[39m\u001b[39m\"\u001b[39m, config)\n\u001b[0;32m---> 60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m SetFitModel\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m     61\u001b[0m         path, \n\u001b[1;32m     62\u001b[0m         use_differentiable_head\u001b[39m=\u001b[39;49muse_differentiable_head, \n\u001b[1;32m     63\u001b[0m         non_differentiable_model_head\u001b[39m=\u001b[39;49mnon_differentiable_model_head) \\\n\u001b[1;32m     64\u001b[0m     \u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m     65\u001b[0m \u001b[39melse\u001b[39;00m:  \n\u001b[1;32m     66\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m SetFitModel\u001b[39m.\u001b[39mfrom_pretrained(\n\u001b[1;32m     67\u001b[0m         model_type, \n\u001b[1;32m     68\u001b[0m         use_differentiable_head\u001b[39m=\u001b[39muse_differentiable_head, \n\u001b[1;32m     69\u001b[0m         non_differentiable_model_head\u001b[39m=\u001b[39mnon_differentiable_model_head) \\\n\u001b[1;32m     70\u001b[0m     \u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/miniconda3/envs/raft-baselines/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/raft-baselines/lib/python3.8/site-packages/huggingface_hub/hub_mixin.py:159\u001b[0m, in \u001b[0;36mModelHubMixin.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, force_download, resume_download, proxies, token, cache_dir, local_files_only, revision, **model_kwargs)\u001b[0m\n\u001b[1;32m    156\u001b[0m         config \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f)\n\u001b[1;32m    157\u001b[0m     model_kwargs\u001b[39m.\u001b[39mupdate({\u001b[39m\"\u001b[39m\u001b[39mconfig\u001b[39m\u001b[39m\"\u001b[39m: config})\n\u001b[0;32m--> 159\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_from_pretrained(\n\u001b[1;32m    160\u001b[0m     model_id\u001b[39m=\u001b[39;49m\u001b[39mstr\u001b[39;49m(model_id),\n\u001b[1;32m    161\u001b[0m     revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    162\u001b[0m     cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    163\u001b[0m     force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    164\u001b[0m     proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    165\u001b[0m     resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    166\u001b[0m     local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    167\u001b[0m     token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m    168\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[1;32m    169\u001b[0m )\n",
      "File \u001b[0;32m~/raft-baselines/src/setfit/modeling.py:522\u001b[0m, in \u001b[0;36mSetFitModel._from_pretrained\u001b[0;34m(cls, model_id, revision, cache_dir, force_download, proxies, resume_download, local_files_only, use_auth_token, multi_target_strategy, use_differentiable_head, non_differentiable_model_head, normalize_embeddings, **model_kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    506\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_from_pretrained\u001b[39m(\n\u001b[1;32m    507\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[1;32m    521\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mSetFitModel\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 522\u001b[0m     model_body \u001b[39m=\u001b[39m SentenceTransformer(model_id, cache_folder\u001b[39m=\u001b[39;49mcache_dir, use_auth_token\u001b[39m=\u001b[39;49muse_auth_token)\n\u001b[1;32m    523\u001b[0m     target_device \u001b[39m=\u001b[39m model_body\u001b[39m.\u001b[39m_target_device\n\u001b[1;32m    524\u001b[0m     model_body\u001b[39m.\u001b[39mto(target_device)  \u001b[39m# put `model_body` on the target device\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/raft-baselines/lib/python3.8/site-packages/sentence_transformers/SentenceTransformer.py:77\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[0;34m(self, model_name_or_path, modules, device, cache_folder, use_auth_token)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m     \u001b[39m#Not a path, load from hub\u001b[39;00m\n\u001b[1;32m     76\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m model_name_or_path \u001b[39mor\u001b[39;00m model_name_or_path\u001b[39m.\u001b[39mcount(\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 77\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mPath \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m not found\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(model_name_or_path))\n\u001b[1;32m     79\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m model_name_or_path \u001b[39mand\u001b[39;00m model_name_or_path\u001b[39m.\u001b[39mlower() \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m basic_transformer_models:\n\u001b[1;32m     80\u001b[0m         \u001b[39m# A model from sentence-transformers\u001b[39;00m\n\u001b[1;32m     81\u001b[0m         model_name_or_path \u001b[39m=\u001b[39m __MODEL_HUB_ORGANIZATION__ \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m model_name_or_path\n",
      "\u001b[0;31mValueError\u001b[0m: Path /root/raft-baselines/src/raft_baselines/models/banking_77 not found"
     ]
    }
   ],
   "source": [
    "from raft_baselines.classifiers import SetFitClassifier\n",
    "\n",
    "classifier = SetFitClassifier(\n",
    "    training_data=banking_77_ought,\n",
    "    config=\"banking_77\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "banking_77_full = datasets.load_dataset(\n",
    "    \"banking77\", split=\"train\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the two datasets\n",
    "\n",
    "# first find all the classes in the ought dataset\n",
    "ought_classes = list(banking_77_ought.features[\"Label\"].names[1:])\n",
    "other_classes = list(banking_77_full.features[\"label\"].names)\n",
    "\n",
    "num_per_class = 8\n",
    "class_counts = {}\n",
    "\n",
    "new_examples = []\n",
    "for example in banking_77_full:\n",
    "    label = example[\"label\"]\n",
    "    text = example[\"text\"]\n",
    "    ought_index = ought_classes.index(other_classes[label])\n",
    "    ought_class_number = ought_index + 1\n",
    "    \n",
    "    if label not in class_counts:\n",
    "        class_counts[label] = 0\n",
    "    \n",
    "    if class_counts[label] < num_per_class:\n",
    "        class_counts[label] += 1\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    new_examples.append({\n",
    "        \"Query\": text,\n",
    "        \"Label\": ought_class_number,\n",
    "        \"ID\": 0\n",
    "    })\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a new dataset\n",
    "full_list = banking_77_ought.to_list() + new_examples\n",
    "full_dataset = datasets.Dataset.from_list(full_list, split=\"train\", features=banking_77_ought.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from raft_baselines.classifiers import SetFitClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = SetFitClassifier(\n",
    "    full_dataset,\n",
    "    config=\"banking_77\",\n",
    "    model_head=RandomForestClassifier,\n",
    "    model_type=\"sentence-transformers/paraphrase-mpnet-base-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "classifier.model.save_pretrained(\"../models/banking_77\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from raft_baselines.classifiers import SetFitClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "systematic_review_inclusion_dataset = datasets.load_dataset(\n",
    "    \"ought/raft\", \"systematic_review_inclusion\", split=\"train\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = [\n",
    "    {\n",
    "        \"Title\": \"The Psychology of Giving: Understanding Donor Motivations in Charitable Donations\",\n",
    "        \"Abstract\": \"This paper presents a systematic review of the psychological factors influencing monetary donations to charitable causes. It synthesizes findings from various studies to identify key motivators such as altruism, social recognition, and emotional responses. The review also discusses how these factors vary across different demographics and cultural backgrounds, providing insights for more effective fundraising strategies.\",\n",
    "        \"Journal\": \"Journal of Behavioral Philanthropy\"\n",
    "    },\n",
    "    {\n",
    "        \"Title\": \"Corporate Social Responsibility and Charitable Giving: A Review of Business-Driven Philanthropy\",\n",
    "        \"Abstract\": \"This review examines the role of corporate social responsibility (CSR) initiatives in promoting monetary charitable donations. It analyzes peer-reviewed literature to assess the impact of CSR campaigns on both corporate giving and encouraging employee donations. The paper highlights successful CSR strategies and explores the implications of corporate philanthropy for broader societal welfare.\",\n",
    "        \"Journal\": \"Business Ethics and Philanthropy Quarterly\"\n",
    "    },\n",
    "    {\n",
    "        \"Title\": \"Digital Innovations in Fundraising: A Systematic Review of Online Donation Platforms\",\n",
    "        \"Abstract\": \"This paper provides a comprehensive review of the effectiveness of online donation platforms in facilitating monetary charitable contributions. It evaluates various digital tools and technologies, including crowdfunding and social media fundraising, and their success in different contexts. The review also assesses user experience, trust factors, and the role of digital storytelling in enhancing online giving.\",\n",
    "        \"Journal\": \"Journal of Digital Philanthropy\"\n",
    "    },\n",
    "    {\n",
    "        \"Title\": \"Comparative Analysis of Direct Mail versus Online Appeals in Charitable Giving\",\n",
    "        \"Abstract\": \"This systematic review compares the effectiveness of direct mail campaigns versus online appeals in soliciting monetary donations for charities. The paper analyzes peer-reviewed studies to evaluate the success rates, donor demographics, and cost-effectiveness of each method. It also examines how the integration of digital and traditional methods can optimize donation campaigns in varying socioeconomic and age groups.\",\n",
    "        \"Journal\": \"International Review of Charitable Marketing\"\n",
    "    },\n",
    "    {\n",
    "        \"Title\": \"Influence of Celebrity Endorsements on Charitable Contributions: A Systematic Review\",\n",
    "        \"Abstract\": \"This review explores the impact of celebrity endorsements on monetary charitable donations. It systematically analyzes data from various studies to assess the extent to which celebrity involvement in charity campaigns affects donor engagement and contribution levels. The paper also investigates the role of celebrity credibility and alignment with the cause in shaping public response to donation appeals.\",\n",
    "        \"Journal\": \"Journal of Celebrity and Philanthropy Studies\"\n",
    "    },\n",
    "    {\n",
    "        \"Title\": \"Tax Incentives and Their Effect on Charitable Donations: A Global Perspective\",\n",
    "        \"Abstract\": \"This paper provides a systematic review of the impact of tax incentives on promoting monetary charitable donations across different countries. It evaluates peer-reviewed research to determine the effectiveness of tax deductions and credits as motivators for charitable giving. The review also discusses how different tax policies influence donation behaviors in diverse economic and cultural contexts.\",\n",
    "        \"Journal\": \"Transnational Nonprofit Policy Review\"\n",
    "    },\n",
    "    {\n",
    "        \"Title\": \"The Impact of Social Media Campaigns on Charitable Donations: A Systematic Review\",\n",
    "        \"Abstract\": \"This paper presents a comprehensive systematic review of existing literature on the efficacy of social media campaigns in boosting monetary charitable donations. It synthesizes data from various studies to evaluate the strategies that have proven most effective in different contexts. This review covers a range of social media platforms and assesses their impact on diverse populations, providing insights into the mechanics of successful campaigns and their scalability.\",\n",
    "        \"Journal\": \"Journal of Philanthropic Studies\"\n",
    "    },\n",
    "    {\n",
    "        \"Title\": \"Effectiveness of Match-Funding as a Catalyst for Increasing Charitable Giving: A Meta-Analysis\",\n",
    "        \"Abstract\": \"This paper conducts a meta-analysis of studies examining match-funding as a method to increase monetary donations to charities. It aggregates data from multiple peer-reviewed studies to assess the overall effectiveness of match-funding strategies across various contexts and demographics. The analysis focuses on understanding the psychological drivers behind increased donations due to match-funding and suggests best practices for its implementation.\",\n",
    "        \"Journal\": \"Review of Nonprofit and Volunteering Sector Research\"\n",
    "    },\n",
    "    {\n",
    "        \"Title\": \"Narrative Persuasion in Charitable Organizations: A Systematic Review\",\n",
    "        \"Abstract\": \"This review investigates the role of narrative persuasion in enhancing monetary charitable donations. It compiles and analyzes data from various studies to understand how storytelling and emotional appeals influence donor behavior. The paper explores different narrative techniques and their effectiveness in various cultural and socio-economic contexts, providing a critical assessment of current practices in the field.\",\n",
    "        \"Journal\": \"Global Journal of Charity Research\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in new_data:\n",
    "    d[\"ID\"] = 0\n",
    "    d[\"Label\"] = 1\n",
    "    d[\"Authors\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_list = systematic_review_inclusion_dataset.to_list() + new_data\n",
    "full_dataset = datasets.Dataset.from_list(full_list, split=\"train\", features=systematic_review_inclusion_dataset.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
      "Map: 100%|██████████| 59/59 [00:00<00:00, 5044.62 examples/s]\n",
      "Generating Training Pairs: 100%|██████████| 20/20 [00:00<00:00, 293.70it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 2360\n",
      "  Num epochs = 1\n",
      "  Total optimization steps = 148\n",
      "  Total train batch size = 16\n",
      "Iteration: 100%|██████████| 148/148 [09:14<00:00,  3.74s/it]\n",
      "Epoch: 100%|██████████| 1/1 [09:14<00:00, 554.09s/it]\n"
     ]
    }
   ],
   "source": [
    "classifier = SetFitClassifier(\n",
    "    full_dataset,\n",
    "    config=\"systematic_review_inclusion\",\n",
    "    model_head=RandomForestClassifier,\n",
    "    model_type=\"sentence-transformers/paraphrase-mpnet-base-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.model.save_pretrained(\"../models/systematic_review_inclusion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "raft-baselines",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
